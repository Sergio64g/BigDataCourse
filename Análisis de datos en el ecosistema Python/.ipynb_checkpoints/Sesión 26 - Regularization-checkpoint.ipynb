{"cells":[{"cell_type":"code","execution_count":1,"id":"73f242d2","metadata":{"id":"73f242d2","executionInfo":{"status":"error","timestamp":1652717634390,"user_tz":-120,"elapsed":7,"user":{"displayName":"Aroa Fernández","userId":"11771938204077993402"}},"outputId":"9ce96b94-35c7-4077-a4d5-2a2017a89f0a","colab":{"base_uri":"https://localhost:8080/","height":130}},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7499d640d0d0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Fuentes:\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["Fuentes:\n","    \n","    - https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/"]},{"cell_type":"markdown","id":"d988f0fd","metadata":{"id":"d988f0fd"},"source":["- Regularization: \n"," - Weight regularization\n"," - Dropout\n"," - Batch normalization\n"," - Data Augmentation (más adelante)\n"]},{"cell_type":"markdown","id":"1562215a","metadata":{"id":"1562215a"},"source":["### Weight regularization\n","\n","- El modelo más sencillo (el que tenga menos parámetros) que funcione bien\n","- Solucionar los problemas de overfitting en deep learning no es una tarea sencilla\n","- Generalmente se prefieren los modelos con parámetros pequeños, por lo que se penalizan los valores grandes\n"," - Coste proporcional al valor absoluto (L1) o proporcional a la raiz cuadrada del valor (L2)\n"," \n"," \n","### Dropout\n"," \n","- Desactivar neuronas aleatoriamente (i.e. poner a 0 en output features de una capa)\n","- Dropout rate determina la proporcion de neuronas a desactivar\n","- Funciona al eliminar patrones espurios (evita overfitting)\n","\n","### Batch normalization\n","\n","- Resta la media y divide entre la desviación típica de los datos del batch -> Estandarización de features\n","\n","![image-2.png](attachment:image-2.png)\n","\n","- Se suele situar en la salida de la capa (tras la función de activación)\n","- Mejora el entrenamiento de la red -> Mayor eficiencia computacional\n","- Permite el uso de valores de learning rate más altos\n","- Se puede considerar como un método de regularización aunque no es su principal ventaja. Dropout y L1/L2 aportan mayor regularización\n","- Existen variantes como Layer normalization, Instance normalization o Group normalization (CNNs)\n","![image.png](attachment:image.png)"]},{"cell_type":"markdown","id":"a99ac9e9","metadata":{"id":"a99ac9e9"},"source":["# Práctica con REUTERS"]},{"cell_type":"markdown","id":"1e63a1e9","metadata":{"id":"1e63a1e9"},"source":["### Carga de los datos"]},{"cell_type":"code","execution_count":null,"id":"ea8bf144","metadata":{"id":"ea8bf144"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","# Importamos el dataset REUTERS y cargamos los datos\n","reuters = tf.keras.datasets.reuters\n","WORD_LIMIT = 10000\n","(training_data, training_labels), (testing_data, testing_labels) = reuters.load_data(num_words=WORD_LIMIT)\n","print(training_data.shape, training_labels.shape, testing_data.shape,testing_labels.shape)"]},{"cell_type":"markdown","id":"90ef727b","metadata":{"id":"90ef727b"},"source":["### Inspección del conjunto de datos"]},{"cell_type":"code","execution_count":null,"id":"c97ede7c","metadata":{"id":"c97ede7c"},"outputs":[],"source":["# Los datos son numericos para decodificarlos, se puede usar reuters.get_word_index()\n","word_index = reuters.get_word_index()\n","reverse_word_index = dict({value : key for key, value in word_index.items()})\n","decoded = ' '.join(\n","    [reverse_word_index.get(i-3,'?') for i in training_data[5248]]\n",")\n","decoded"]},{"cell_type":"markdown","id":"0dfc67d6","metadata":{"id":"0dfc67d6"},"source":["### One hot encoding"]},{"cell_type":"code","execution_count":null,"id":"03da189b","metadata":{"id":"03da189b"},"outputs":[],"source":["# Función auxiliar para representar las palabras ( en números \n","import numpy as np\n","# one hot encoding del input, vector con cada indice indicando si una palabra esta presente\n","def one_hot_encode(data):\n","    encoded = np.zeros((len(data),WORD_LIMIT))\n","    for i, v in enumerate(data):\n","        encoded[i,v] = 1 # localiza las columnas del genero correspondiente, marca con 1\n","    return encoded"]},{"cell_type":"code","execution_count":null,"id":"ab527346","metadata":{"id":"ab527346"},"outputs":[],"source":["# Convertimos palabras en números\n","x_train = one_hot_encode(training_data)\n","x_test = one_hot_encode(testing_data)\n","print(x_train.shape)\n","print(x_test.shape)"]},{"cell_type":"code","execution_count":null,"id":"3632e881","metadata":{"id":"3632e881"},"outputs":[],"source":["print(x_test[3])"]},{"cell_type":"code","execution_count":null,"id":"a752a0e0","metadata":{"id":"a752a0e0"},"outputs":[],"source":["from tensorflow.keras.utils import to_categorical\n","y_train = to_categorical(training_labels)\n","y_test = to_categorical(testing_labels)\n","print(y_train.shape)\n","print(y_test.shape)"]},{"cell_type":"markdown","id":"e1b40603","metadata":{"id":"e1b40603"},"source":["### Red Neuronal"]},{"cell_type":"code","execution_count":null,"id":"d245423e","metadata":{"id":"d245423e"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","# Vamos a codificar la topología de nuestro MLP\n","model = Sequential()\n","model.add(Dense(128,activation='relu',input_shape=(WORD_LIMIT,)))\n","model.add(Dense(64,activation='relu'))\n","model.add(Dense(46,activation='softmax')) # Reparto de la unidad de probabilidad entre num_classes"]},{"cell_type":"code","execution_count":null,"id":"ec10152a","metadata":{"id":"ec10152a"},"outputs":[],"source":["# Se compila\n","\n","model.compile(optimizer='adam',\n","               loss='categorical_crossentropy', # ideal para clasificacion multiclase\n","               metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"87216fa6","metadata":{"id":"87216fa6"},"outputs":[],"source":["# Se entrena\n","\n","H = model.fit(x_train,y_train,epochs=15,batch_size=32, validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"id":"c6240430","metadata":{"id":"c6240430"},"outputs":[],"source":["# Análisis del proceso de entrenamiento\n","\n","import matplotlib.pyplot as plt\n","# Muestro gráfica de accuracy y losses\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"id":"a18d1a28","metadata":{"id":"a18d1a28"},"outputs":[],"source":["# Evaluación del modelo\n","\n","print(\"[INFO]: Evaluando red neuronal...\")\n","model.predict(x_test)\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('Loss {}, accuracy {}'.format(loss,accuracy))"]},{"cell_type":"markdown","id":"d0b77a21","metadata":{"id":"d0b77a21"},"source":["## Regularization"]},{"cell_type":"markdown","id":"51435312","metadata":{"id":"51435312"},"source":["#### Weight regularization L1/L2"]},{"cell_type":"code","execution_count":null,"id":"5264358e","metadata":{"id":"5264358e"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import regularizers\n","\n","\n","model_reg = Sequential()\n","model_reg.add(Dense(128,activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(WORD_LIMIT,)))\n","model_reg.add(Dense(64,activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","model_reg.add(Dense(46,activation='softmax')) "]},{"cell_type":"code","execution_count":null,"id":"4701f556","metadata":{"id":"4701f556"},"outputs":[],"source":["model_reg.compile(optimizer='adam',\n","               loss='categorical_crossentropy', #clasificación multiclase\n","               metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"7fea57c3","metadata":{"id":"7fea57c3"},"outputs":[],"source":["H = model_reg.fit(x_train,y_train,epochs=15,batch_size=32, validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"id":"6a1d2ada","metadata":{"id":"6a1d2ada"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"id":"02f771bb","metadata":{"id":"02f771bb"},"outputs":[],"source":["# Evaluación del modelo\n","\n","print(\"[INFO]: Evaluando red neuronal...\")\n","model_reg.predict(x_test)\n","loss, accuracy = model_reg.evaluate(x_test, y_test)\n","print('Loss {}, accuracy {}'.format(loss,accuracy))"]},{"cell_type":"markdown","id":"340fa6d2","metadata":{"id":"340fa6d2"},"source":["#### Dropout"]},{"cell_type":"code","execution_count":null,"id":"73bc2866","metadata":{"id":"73bc2866"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","model_drop = Sequential()\n","model_drop.add(Dense(128,activation='relu', input_shape=(WORD_LIMIT,)))\n","\n","model_drop.add(Dropout(0.75))\n","model_drop.add(Dense(64,activation='relu'))\n","\n","model_drop.add(Dropout(0.75))\n","model_drop.add(Dense(46,activation='softmax')) "]},{"cell_type":"code","execution_count":null,"id":"64590272","metadata":{"id":"64590272"},"outputs":[],"source":["model_drop.compile(optimizer='adam',\n","               loss='categorical_crossentropy', # clasificacion multiclase\n","               metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"92becad3","metadata":{"id":"92becad3"},"outputs":[],"source":["H = model_drop.fit(x_train,y_train,epochs=15,batch_size=32, validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"id":"40d8aa83","metadata":{"id":"40d8aa83"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"id":"19dd188a","metadata":{"id":"19dd188a"},"outputs":[],"source":["# Evaluación del modelo\n","print(\"[INFO]: Evaluando red neuronal...\")\n","model_drop.predict(x_test)\n","loss, accuracy = model_drop.evaluate(x_test, y_test)\n","print('Loss {}, accuracy {}'.format(loss,accuracy))"]},{"cell_type":"markdown","id":"ee9de864","metadata":{"id":"ee9de864"},"source":["#### Batch Normalization"]},{"cell_type":"code","execution_count":null,"id":"249aedf1","metadata":{"id":"249aedf1"},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, BatchNormalization\n","\n","model_bn = Sequential()\n","model_bn.add(Dense(128,activation='relu', input_shape=(WORD_LIMIT,)))\n","model_bn.add(BatchNormalization())\n","model_bn.add(Dropout(0.75))\n","model_bn.add(Dense(64,activation='relu'))\n","model_bn.add(BatchNormalization())\n","model_bn.add(Dropout(0.75))\n","model_bn.add(Dense(46,activation='softmax')) "]},{"cell_type":"code","execution_count":null,"id":"5c834b17","metadata":{"id":"5c834b17"},"outputs":[],"source":["model_bn.compile(optimizer='adam',\n","               loss='categorical_crossentropy', #clasificacion multiclase\n","               metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"20646edd","metadata":{"id":"20646edd"},"outputs":[],"source":["H = model_bn.fit(x_train,y_train,epochs=15,batch_size=32, validation_split=0.2)"]},{"cell_type":"code","execution_count":null,"id":"9ef45924","metadata":{"id":"9ef45924"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"id":"dc88867e","metadata":{"id":"dc88867e"},"outputs":[],"source":["# Evaluación del modelo\n","print(\"[INFO]: Evaluando red neuronal...\")\n","model_bn.predict(x_test)\n","loss, accuracy = model_bn.evaluate(x_test, y_test)\n","print('Loss {}, accuracy {}'.format(loss,accuracy))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Sesión 26 - Regularization.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}