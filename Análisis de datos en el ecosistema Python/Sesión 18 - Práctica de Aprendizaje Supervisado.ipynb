{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Práctico de Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo y descripción del problema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **objetivo** del problema es implementar modelos de regresión para 3 datasets distintos, evaluando la bondad de sus predicciones y cuantificando los errores producidos por los modelos.\n",
    "\n",
    "Para ello, se van a seguir los siguientes pasos:\n",
    "\n",
    "- Comprensión del problema y carga de datos\n",
    "- Preprocesado y análisis inicial de los datos\n",
    "- Partición externa de los datos\n",
    "- Selección de atributos\n",
    "- Estandarización de atriutos\n",
    "- Validación cruzada para optimizar los hiperparámetros\n",
    "- Modelado con modelos de regresión (OLS y KNN Regressor)\n",
    "- Evaluación de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los datasets con los que se va a trabajar:\n",
    "\n",
    "**Advertising**\n",
    "- Conjunto de datos sobre el gasto de diversos anuncios en campañas publicitarias en diferentes medios.\n",
    "- Predicción: ventas conseguidas según el gasto invertido en publicidad\n",
    "- Features:\n",
    " - TV: gasto en TV\n",
    " - Radio: gasto en Radio\n",
    " - Newspaper: gasto en Newspaper\n",
    "\n",
    "**Airfoil**\n",
    "\n",
    "- Conjunto de datos de la NASA, obtenido de una serie de pruebas aerodinámicas y acústicas de secciones de palas aerodinámicas bidimensionales y tridimensionales realizadas en un túnel de viento anecoico. El dataset comprende superficies aerodinámicas NACA 0012 de diferentes tamaños a varias velocidades de túnel de viento y ángulos de ataque. El tramo del perfil aerodinámico y la posición del observador fueron los mismos en todos los experimentos. \n",
    "- Predicción: nivel de presión sonora en decibelios\n",
    "- Features:\n",
    " - Frequency, in Hertzs.\n",
    " - Angle of attack, in degrees.\n",
    " - Chord length, in meters.\n",
    " - Free-stream velocity, in meters per second.\n",
    " - Suction side displacement thickness, in meters. \n",
    "\n",
    "\n",
    "**California housing**\n",
    "- Conjunto de datos de las diferentes características que presenta el vino así como la calidad del mismo.\n",
    "- Predicción: value (valor de la casa)\n",
    "- Features:\n",
    " - MedInc\n",
    " - HouseAge\n",
    " - AveRooms\t\n",
    " - AveBedrms\t\n",
    " - Population\t\n",
    " - AveOccup\t\n",
    " - Latitude\t\n",
    " - Longitude\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_regression,f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import cross_validate, KFold, cross_val_predict, train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ruta = os.path.join(\"datasets\", \"Advertising.csv\")\n",
    "fichero = open(ruta)\n",
    "data_1 = pd.read_csv(ruta)\n",
    "fichero.close()\n",
    "\n",
    "ruta = os.path.join(\"datasets\", \"airfoil_self_noise.dat\")\n",
    "fichero = open(ruta)\n",
    "data_2 = pd.read_csv(ruta, sep=\"\\t\", names = [\"frequency\", \"angle_of_attack\", \"chord_length\", \n",
    "                                                 \"free_stream_velocity\", \"Suction_thickness\", \"pressure_level\"])\n",
    "fichero.close()\n",
    "\n",
    "# Carga de datos.\n",
    "dataset = datasets.fetch_california_housing(as_frame=True)\n",
    "data_3 = dataset.data\n",
    "data_3['Value'] = dataset.target\n",
    "\n",
    "print(np.shape(data_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dic = {'data_1': data_1,'data_2': data_2, 'data_3':data_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hacen varios chequeos y se aplican técnicas de preprocesado de datos para mejorar la comprensión y estructura de los datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tratamiento de valores faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de valores faltantes\n",
    "\n",
    "print(\"---- Advertising ----\")\n",
    "print(data_1.isnull().sum())\n",
    "print('---- Airfoil ----')\n",
    "print(data_2.isnull().sum())\n",
    "print('---- California ----')\n",
    "print(data_3.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advertising\n",
    "data_1[\"Radio\"].fillna(data_1[\"Radio\"].mean(),inplace=True)\n",
    "data_1[\"Newspaper\"].fillna(data_1[\"Newspaper\"].mean(),inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir una función para estudiar los outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separación de atributos y variable target**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que los cálculos sean más sencillos, vamos a crear dos diccionarios, uno con los atributos de cada uno de los datasets y otro con las variables target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = {\n",
    "    'ADS': data_1.iloc[:,:-1],\n",
    "    'AIR': data_2.iloc[:,:-1],\n",
    "    'CALIFORNIA': data_3.iloc[:,:-1]\n",
    "}\n",
    "\n",
    "y = {\n",
    "    'ADS': data_1.iloc[:,-1],\n",
    "    'AIR': data_2.iloc[:,-1],\n",
    "    'CALIFORNIA': data_3.iloc[:,-1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se comprueba que se ha hecho bien con el tamaño de los datasets\n",
    "for nombre, exp in X.items():\n",
    "    print(nombre)\n",
    "    print(exp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partición hold out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= {}\n",
    "y_train = {}\n",
    "X_test = {}\n",
    "y_test = {}\n",
    "\n",
    "for nombre, exp in X.items():\n",
    "    X_train[nombre],X_test[nombre],y_train[nombre],y_test[nombre] = train_test_split(X[nombre],y[nombre], \n",
    "                                                                                     test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" ------------------------\")\n",
    "for key,item in X_train.items():\n",
    "    print(key)\n",
    "    print(item.shape)\n",
    "print(\" ------------------------\")\n",
    "for key,item in y_train.items():\n",
    "    print(key)\n",
    "    print(item.shape)\n",
    "print(\" ------------------------\")\n",
    "for key,item in X_test.items():\n",
    "    print(key)\n",
    "    print(item.shape)\n",
    "print(\" ------------------------\")\n",
    "for key,item in X_test.items():\n",
    "    print(key)\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selección de atributos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobación del tamaño de los datasets de entrenamiento\n",
    "for key,item in X_train.items():\n",
    "    print(key)\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variance_T = {}\n",
    "X_train_sel = {}\n",
    "for nombre, exp in X_train.items():\n",
    "    selector = VarianceThreshold(0.3)\n",
    "    Variance_T[nombre] = selector.fit(X_train[nombre])\n",
    "    X_train_sel[nombre] = Variance_T[nombre].transform(X_train[nombre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,item in X_train_sel.items():\n",
    "    print(key)\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estandarización de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,item in X_train.items():\n",
    "    print(key)\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardizer = {}\n",
    "X_train_std = {}\n",
    "\n",
    "for nombre, exp in X_train_sel.items():\n",
    "    estandarizador = preprocessing.StandardScaler()\n",
    "    standardizer[nombre] = estandarizador.fit(X_train_sel[nombre])\n",
    "    X_train_std[nombre] = standardizer[nombre].transform(X_train_sel[nombre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,item in X_train_std.items():\n",
    "    print(key)\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparación de modelos con cross_val_score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los algoritmos dentro de un diccionario y se hacen distintas ejecuciones cambiando los hiperparámetros\n",
    "# del modelo hasta conseguir aquellos que den mejor resultado\n",
    "\n",
    "k=5\n",
    "algoritmos = {'OLS' : LinearRegression(),\n",
    "\n",
    "              'KNN' : KNeighborsRegressor(n_neighbors = k, weights='distance', metric='euclidean', algorithm='kd_tree'),\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace validación cruzada con 10 bolsas y se obtiene la metrica MAE para ambos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {}\n",
    "\n",
    "for nombre, exp in X_train_std.items():\n",
    "    resultados[str('OLS_')+nombre] = cross_val_score(algoritmos['OLS'], X_train_std[nombre], y_train[nombre], \n",
    "                                                     cv = KFold(n_splits=10, shuffle=True, random_state=42),\n",
    "                                                     scoring='neg_mean_absolute_error')\n",
    "    print(\"OLS\", nombre, \"cross_val_MAE:   %0.4f +/- %0.4f\" % (-resultados[str('OLS_')+nombre].mean(), \n",
    "                                                                resultados[str('OLS_')+nombre].std()))\n",
    "\n",
    "    resultados[str('KNN')+nombre] = cross_val_score(algoritmos['KNN'], X_train_std[nombre], y_train[nombre], \n",
    "                                                     cv = KFold(n_splits=10, shuffle=True, random_state=42),\n",
    "                                                     scoring='neg_mean_absolute_error')\n",
    "    print(\"KNN\", nombre, \"cross_val_MAE:   %0.4f +/- %0.4f\" % ( -resultados[str('KNN')+nombre].mean(), \n",
    "                                                                 resultados[str('KNN')+nombre].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo final**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el paso anterior se ha utilizado validación cruzada para optimizar los hiperpámetros, y ahora se va a entrenar el modelo con todos los datos de entrenamiento. Los resultados se guardan en un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, exp in X_train_std.items():\n",
    "    print(exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_definitivo_ols = {}\n",
    "modelo_definitivo_knn = {}\n",
    "\n",
    "for nombre, exp in X_train_std.items():\n",
    "    modelo_definitivo_ols[nombre + str('_OLS')] = algoritmos['OLS'].fit(X_train_std[nombre], y_train[nombre])\n",
    "    \n",
    "for nombre, exp in X_train_std.items():\n",
    "    modelo_definitivo_knn[nombre + str('_KNN')] = algoritmos['KNN'].fit(X_train_std[nombre], y_train[nombre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_ols = {}\n",
    "y_train_pred_knn = {}\n",
    "for nombre, exp in X_train_std.items():\n",
    "    y_train_pred_ols[nombre + str('_OLS')] = cross_val_predict(modelo_definitivo_ols[nombre + str('_OLS')], \n",
    "                                         X_train_std[nombre], y_train[nombre], \n",
    "                                         cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
    "\n",
    "for nombre, exp in X_train_std.items():\n",
    "    y_train_pred_knn[nombre + str('_KNN')] = cross_val_predict(modelo_definitivo_knn[nombre + str('_KNN')], \n",
    "                                         X_train_std[nombre], y_train[nombre], \n",
    "                                         cv=KFold(n_splits=10, shuffle=True, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se comprueba el tamaño\n",
    "for nombre, exp in y_train_pred_ols.items():\n",
    "    print(nombre)\n",
    "    print(exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se comprueba el tamaño\n",
    "for nombre, exp in y_train_pred_knn.items():\n",
    "    print(nombre)\n",
    "    print(exp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estandarización y selección de atributos del conjunto de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, exp in X_test.items():\n",
    "    print(nombre)\n",
    "    print(exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, exp in X_train.items():\n",
    "    print(nombre)\n",
    "    print(exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel = {}\n",
    "for nombre, exp in X_test.items():\n",
    "    X_test_sel[nombre] = Variance_T[nombre].transform(X_test[nombre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = {}\n",
    "for nombre, exp in X_test_sel.items():\n",
    "    X_test_std[nombre] = standardizer[nombre].transform(X_test_sel[nombre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, exp in X_test_std.items():\n",
    "    print(nombre)\n",
    "    print(exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se utilizan los modelos de KNN y OLS entrenados con el conjunto de entrenamiento para hacer predicciones con el conjunto \n",
    "# de test y evaluar los modelos creados.\n",
    "\n",
    "y_test_pred_ols = {}\n",
    "y_test_pred_knn = {}\n",
    "for nombre, exp in X_test_std.items():\n",
    "    y_test_pred_ols[nombre + str('_OLS')] = cross_val_predict(modelo_definitivo_ols[nombre + str('_OLS')], \n",
    "                                         X_test_std[nombre], y_test[nombre], \n",
    "                                         cv=KFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "\n",
    "for nombre, exp in X_test_std.items():\n",
    "    y_test_pred_knn[nombre + str('_KNN')] = cross_val_predict(modelo_definitivo_knn[nombre + str('_KNN')], \n",
    "                                         X_test_std[nombre], y_test[nombre], \n",
    "                                         cv=KFold(n_splits=5, shuffle=True, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métricas: MAE, RMSE, MAPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def evaluacion(y_true, y_pred, metricas):\n",
    "    res = {}\n",
    "    for nombre, funcion in metricas.items():\n",
    "        res[nombre] = funcion(y_true, y_pred)\n",
    "    return res\n",
    "\n",
    "\n",
    "metricas = {\n",
    "  'MAE':  metrics.mean_absolute_error,\n",
    "  'RMSE': lambda y, y_pred:\n",
    "          math.sqrt(metrics.mean_squared_error(y, y_pred)),\n",
    "  'MAPE': lambda y, y_pred:\n",
    "          np.mean(np.abs((y - y_pred) / y)) * 100,\n",
    "  'R2':   metrics.r2_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluación del conjunto de entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas correspondientes a LinearRegression()\n",
    "\n",
    "import math\n",
    "for nombre, exp in y_train.items():\n",
    "    print(nombre + str('_OLS'))\n",
    "    MAE =   metricas['MAE'](y_train[nombre], y_train_pred_ols[nombre + str('_OLS')])\n",
    "    RMSE = metricas['RMSE'](y_train[nombre], y_train_pred_ols[nombre + str('_OLS')])\n",
    "    MAPE = metricas['MAPE'](y_train[nombre], y_train_pred_ols[nombre + str('_OLS')])\n",
    "    R2 = metricas['R2'](y_train[nombre], y_train_pred_ols[nombre + str('_OLS')])\n",
    "    \n",
    "    print('MAE:  %.4f' % MAE)\n",
    "    print('RMSE: %.4f' % RMSE)\n",
    "    print('MAPE: %.4f' % MAPE)\n",
    "    print('R2: %.4f' % R2)\n",
    "\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del algoritmo KNN y presentación de resultados.\n",
    "for nombre, alg in y_train.items():\n",
    "    results = evaluacion(y_train[nombre], y_train_pred_knn[nombre + str('_KNN')], metricas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluación del conjunto de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombre, exp in y_test.items():\n",
    "    print(nombre + str('_OLS'))\n",
    "    MAE =   metricas['MAE'](y_test[nombre], y_test_pred_ols[nombre + str('_OLS')])\n",
    "    RMSE = metricas['RMSE'](y_test[nombre], y_test_pred_ols[nombre + str('_OLS')])\n",
    "    MAPE = metricas['MAPE'](y_test[nombre],y_test_pred_ols[nombre + str('_OLS')])\n",
    "    R2 =     metricas['R2'](y_test[nombre], y_test_pred_ols[nombre + str('_OLS')])\n",
    "\n",
    "    print('MAE:  %.4f' % MAE)\n",
    "    print('RMSE: %.4f' % RMSE)\n",
    "    print('MAPE: %.4f' % MAPE)\n",
    "    print('R2:   %.4f' % R2)\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación y presentación de resultados.\n",
    "for nombre, alg in y_test.items():\n",
    "    results = evaluacion(y_test[nombre], y_test_pred_knn[nombre + str('_KNN')], metricas)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Explicar los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
