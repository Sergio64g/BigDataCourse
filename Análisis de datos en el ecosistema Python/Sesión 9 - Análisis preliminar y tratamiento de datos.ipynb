{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análisis inicial de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# conda install -c conda-forge pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/Image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ruta = os.path.join(\"datasets\", \"titanic3.csv\")\n",
    "fichero = open(ruta)\n",
    "data = pd.read_csv(ruta)\n",
    "fichero.close()\n",
    "data.head()\n",
    "\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309</td>\n",
       "      <td>1309</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309</td>\n",
       "      <td>1308.000000</td>\n",
       "      <td>295</td>\n",
       "      <td>1307</td>\n",
       "      <td>486</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1307</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>914</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.295479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.809917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.486055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.413500</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.758668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.696922</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pclass     survived                  name   sex          age  \\\n",
       "count   1309.000000  1309.000000                  1309  1309  1046.000000   \n",
       "unique          NaN          NaN                  1307     2          NaN   \n",
       "top             NaN          NaN  Connolly, Miss. Kate  male          NaN   \n",
       "freq            NaN          NaN                     2   843          NaN   \n",
       "mean       2.294882     0.381971                   NaN   NaN    29.881135   \n",
       "std        0.837836     0.486055                   NaN   NaN    14.413500   \n",
       "min        1.000000     0.000000                   NaN   NaN     0.166700   \n",
       "25%        2.000000     0.000000                   NaN   NaN    21.000000   \n",
       "50%        3.000000     0.000000                   NaN   NaN    28.000000   \n",
       "75%        3.000000     1.000000                   NaN   NaN    39.000000   \n",
       "max        3.000000     1.000000                   NaN   NaN    80.000000   \n",
       "\n",
       "              sibsp        parch    ticket         fare        cabin embarked  \\\n",
       "count   1309.000000  1309.000000      1309  1308.000000          295     1307   \n",
       "unique          NaN          NaN       929          NaN          186        3   \n",
       "top             NaN          NaN  CA. 2343          NaN  C23 C25 C27        S   \n",
       "freq            NaN          NaN        11          NaN            6      914   \n",
       "mean       0.498854     0.385027       NaN    33.295479          NaN      NaN   \n",
       "std        1.041658     0.865560       NaN    51.758668          NaN      NaN   \n",
       "min        0.000000     0.000000       NaN     0.000000          NaN      NaN   \n",
       "25%        0.000000     0.000000       NaN     7.895800          NaN      NaN   \n",
       "50%        0.000000     0.000000       NaN    14.454200          NaN      NaN   \n",
       "75%        1.000000     0.000000       NaN    31.275000          NaN      NaN   \n",
       "max        8.000000     9.000000       NaN   512.329200          NaN      NaN   \n",
       "\n",
       "       boat        body     home.dest  \n",
       "count   486  121.000000           745  \n",
       "unique   27         NaN           369  \n",
       "top      13         NaN  New York, NY  \n",
       "freq     39         NaN            64  \n",
       "mean    NaN  160.809917           NaN  \n",
       "std     NaN   97.696922           NaN  \n",
       "min     NaN    1.000000           NaN  \n",
       "25%     NaN   72.000000           NaN  \n",
       "50%     NaN  155.000000           NaN  \n",
       "75%     NaN  256.000000           NaN  \n",
       "max     NaN  328.000000           NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.294881588999236"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()[\"pclass\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe(include = \"all\")\n",
    "\n",
    "#data.describe(include = \"all\").transpose()\n",
    "\n",
    "# unique: cantidad de valores únicos.\n",
    "# top: valor único con más repeticiones.\n",
    "# freq: cantidad de veces que aparece el valor más repetido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('New York, NY', 29.8811345124283)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"home.dest\"].describe()['top'], data[\"age\"].describe()['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    pct_missing = np.mean(data[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pclass     1309 non-null   int64  \n",
      " 1   survived   1309 non-null   int64  \n",
      " 2   name       1309 non-null   object \n",
      " 3   sex        1309 non-null   object \n",
      " 4   age        1046 non-null   float64\n",
      " 5   sibsp      1309 non-null   int64  \n",
      " 6   parch      1309 non-null   int64  \n",
      " 7   ticket     1309 non-null   object \n",
      " 8   fare       1308 non-null   float64\n",
      " 9   cabin      295 non-null    object \n",
      " 10  embarked   1307 non-null   object \n",
      " 11  boat       486 non-null    object \n",
      " 12  body       121 non-null    float64\n",
      " 13  home.dest  745 non-null    object \n",
      "dtypes: float64(3), int64(4), object(7)\n",
      "memory usage: 143.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1309, 14), 18326)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.312469</td>\n",
       "      <td>-0.408106</td>\n",
       "      <td>0.060832</td>\n",
       "      <td>0.018322</td>\n",
       "      <td>-0.558629</td>\n",
       "      <td>-0.034642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>-0.312469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055513</td>\n",
       "      <td>-0.027825</td>\n",
       "      <td>0.082660</td>\n",
       "      <td>0.244265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.408106</td>\n",
       "      <td>-0.055513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.243699</td>\n",
       "      <td>-0.150917</td>\n",
       "      <td>0.178739</td>\n",
       "      <td>0.058809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>0.060832</td>\n",
       "      <td>-0.027825</td>\n",
       "      <td>-0.243699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.373587</td>\n",
       "      <td>0.160238</td>\n",
       "      <td>-0.099961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>0.018322</td>\n",
       "      <td>0.082660</td>\n",
       "      <td>-0.150917</td>\n",
       "      <td>0.373587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221539</td>\n",
       "      <td>0.051099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>-0.558629</td>\n",
       "      <td>0.244265</td>\n",
       "      <td>0.178739</td>\n",
       "      <td>0.160238</td>\n",
       "      <td>0.221539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>-0.034642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058809</td>\n",
       "      <td>-0.099961</td>\n",
       "      <td>0.051099</td>\n",
       "      <td>-0.043110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pclass  survived       age     sibsp     parch      fare      body\n",
       "pclass    1.000000 -0.312469 -0.408106  0.060832  0.018322 -0.558629 -0.034642\n",
       "survived -0.312469  1.000000 -0.055513 -0.027825  0.082660  0.244265       NaN\n",
       "age      -0.408106 -0.055513  1.000000 -0.243699 -0.150917  0.178739  0.058809\n",
       "sibsp     0.060832 -0.027825 -0.243699  1.000000  0.373587  0.160238 -0.099961\n",
       "parch     0.018322  0.082660 -0.150917  0.373587  1.000000  0.221539  0.051099\n",
       "fare     -0.558629  0.244265  0.178739  0.160238  0.221539  1.000000 -0.043110\n",
       "body     -0.034642       NaN  0.058809 -0.099961  0.051099 -0.043110  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separar columnas numéricas del resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas numéricas: \n",
      "['pclass' 'survived' 'age' 'sibsp' 'parch' 'fare' 'body']\n",
      "\n",
      "\n",
      "Columnas NO numéricas: \n",
      "['name' 'sex' 'ticket' 'cabin' 'embarked' 'boat' 'home.dest']\n"
     ]
    }
   ],
   "source": [
    "data_numeric = data.select_dtypes(include=[np.number])\n",
    "numeric_cols = data_numeric.columns.values\n",
    "\n",
    "data_non_numeric = data.select_dtypes(exclude=[np.number])\n",
    "non_numeric_cols = data_non_numeric.columns.values\n",
    "\n",
    "print(\"Columnas numéricas: \")\n",
    "print(numeric_cols)\n",
    "print(\"\\n\")\n",
    "print(\"Columnas NO numéricas: \")\n",
    "print(non_numeric_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis exploratorio con pandas profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se pueden generar los reportes mediante dos interfaces: widgets y HTML report\n",
    "# El principal inconveniente es el timpo que tarda en generar el reporte\n",
    "# Para grandes cantidades de datos, conviene seleccionar las variables que más nos interesen.\n",
    "\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "#from pandas_profiling.utils.cache import cache_file\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Profiling Report\n",
    "profile = ProfileReport(\n",
    "    data, title=\"Titanic Dataset\", html={\"style\": {\"full_width\": True}}, sort=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"your_report.html\")\n",
    "\n",
    "# As a string\n",
    "json_data = profile.to_json()\n",
    "\n",
    "# As a file\n",
    "profile.to_file(\"your_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encontrar los valores faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores nulos por columna\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Cantidad valores nulos\n",
    "print(data.isnull().sum().sum())\n",
    "\n",
    "# numero de no nulos por fila\n",
    "print(data.count(axis=1))\n",
    "\n",
    "# Número de nulos por fila\n",
    "print(data.shape[1] - data.count(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro de las filas con valores faltantes\n",
    "data[data.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos podemos crear un mapa de calor de los datos faltantes\n",
    "# Los amarillos serían los valores faltantes de cada variable\n",
    "\n",
    "cols = data.columns \n",
    "colours = ['#5A9', '#ffff00'] \n",
    "sns.heatmap(data[cols].isnull(), cmap=sns.color_palette(colours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    pct_missing = np.mean(data[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eliminar datos si hay valores faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si optaramos por borrar\n",
    "\n",
    "# data.dropna(how=\"any\") #Borra todas las filas en las que hay al menos un vacío\n",
    "# data.dropna(how=\"all\") # Borra las filas que tienen todo vacío\n",
    "# data.dropna(thresh=2) # Conserva las filas que tienen al menos dos valores vacíos\n",
    "# data.dropna(subset= [\"boat\"]) # Elimina las filas que tienen boat vacío\n",
    "# data.dropna(axis=\"columns\", how=\"any\") # Elimina columnas con al menos un vacío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_mean\"]=data[\"age\"]\n",
    "data\n",
    "\n",
    "# Se puede rellenar los valores faltantes con la media\n",
    "data[\"age_mean\"].fillna(np.mean(np.mean(data[\"age_mean\"])),inplace=True)\n",
    "data[data[\"age\"].isnull()]\n",
    "\n",
    "# Se puede rellenar los valores faltantes con un valor concreto\n",
    "# data[\"age_mean\"].fillna(18,inplace=True)\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En series temporales (el valor más próximo o parecido suele ser el anterior/posterior), no conviene\n",
    "# rellenar con la media, se suele hacer con un par de métodos que rellenan el valor anterior o el posterior\n",
    "\n",
    "# Method to use for filling holes in reindexed Series \n",
    "# pad / ffill: propagate last valid observation forward to next valid \n",
    "# backfill / bfill: use next valid observation to fill gap.\n",
    "\n",
    "#under_age['Age'] = np.nan\n",
    "\n",
    "#data.drop(\"age_ffill\", axis=1, inplace=True)\n",
    "#data.drop(\"age_bfill\", axis=1, inplace=True)\n",
    "\n",
    "data[\"age_ffill\"] = data[\"age\"]\n",
    "data[\"age_bfill\"] = data[\"age\"]\n",
    "\n",
    "data[\"age_ffill\"].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "data[\"age_bfill\"].fillna(method=\"bfill\",inplace=True)\n",
    "data.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"age\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn.impute.SimpleImputer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(\"age_imputer\",axis=1, inplace=True)\n",
    "data[\"age_imputer\"] = data[\"age\"]\n",
    "\n",
    "#imp_mean.fit(data[\"age_imputer\"].reshape(-1,1))\n",
    "\n",
    "\n",
    "data['age_imputer']=pd.DataFrame(imp_mean.fit_transform(data[\"age_imputer\"].values.reshape(-1, 1)))\n",
    "\n",
    "data['age_imputer'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputación de Regresión --> IterativeImputer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#data.drop(\"age_regresion\",axis=1, inplace=True)\n",
    "data[\"age_regresion\"] = data[\"age\"]\n",
    "\n",
    "reg_imputer = IterativeImputer(max_iter=10, random_state=123)\n",
    "\n",
    "data['age_regresion']=pd.DataFrame(reg_imputer.fit_transform(data[\"age_regresion\"].values.reshape(-1,1)))\n",
    "\n",
    "data['age_regresion'].isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_regresion'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputación Knn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_knn\"] = data[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "knn_imputer.fit(data[\"age_knn\"].values.reshape(-1,1))\n",
    "\n",
    "knn_imputer.transform(data[\"age_knn\"].values.reshape(-1,1))\n",
    "\n",
    "#data['age_knn']=pd.DataFrame(knn_imputer.fit_transform(data[\"age_knn\"].values.reshape(-1,1)))\n",
    "data['age_knn'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Con strings se pueden reemplazar los datos nan con el valor que se repite con más frecuencia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\")\n",
    "\n",
    "print(data[\"home.dest\"].value_counts().idxmax())\n",
    "print(data[\"home.dest\"].isnull().sum())\n",
    "\n",
    "data[\"home.dest\"] = data[\"home.dest\"].fillna(data[\"home.dest\"].value_counts().idxmax())\n",
    "print(data[\"home.dest\"].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"home.dest\"].value_counts()\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = pd.Series(['a','b','c','a','c','a','g'])\n",
    "serie.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_dataset\n",
    "df\n",
    "# eliminar\n",
    "# Eliminación de los duplicados en una columna definida\n",
    "df2 = df.drop_duplicates(subset=\"Gender\", keep='last', inplace=False)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tratamiento de outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los outliers o caso atípicos son datos muy diferentes a los demás, debens er contemplados en el contexto del del análisis, pero no siempre se pueden clasificar como buenos o malos.\n",
    "\n",
    "Se suele establecer un umbral para clasificar las observaciones como outliers o no.\n",
    "\n",
    "Pueden ser datos observados o datos que se deben a un error.\n",
    "\n",
    "El problema viene cuando distorsionan de forma problemática el comportamiento del análisis o de los modelos. \n",
    "Incrementan la varianza, y si no están distribuidos aleatoriamente pueden reducir la normalidad de la muestra.\n",
    "También distorsionan el coeficiente de correlación, media, desviación estándar... y en consecuencia todos los análisis estadísticos que las utilizan\n",
    "\n",
    "Hay varios métodos para reconocerlos, algunos útiles son: \n",
    "- Visualizaciones: boxplot, scatterplot, histograma\n",
    "- Estadísticos: Z score \n",
    "    - Para muestras pequeñas +,-2,5 veces z\n",
    "    - Para muestras grandes +,-3 veces z\n",
    "- Estadísticos: IQR\n",
    "    - 1,5 veces IQR\n",
    "    - Cuando supera +-3IQR se consideran **outliers extremos**\n",
    "- EllipticEnvelope \n",
    "    \n",
    "**el algoritmo de envolvente elíptica** crea superficies elípticas en torno a la nube de puntos, y cuanto más alejados están los puntos de dicha nube, mayor probabilidad de que sean outliers. \n",
    "\n",
    "Para construir las superficies elípticas, loa datos se van a centrar (con respecto a la mediana, resta) y escalar (con respecto al IQR, división).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers: To Drop or Not to Drop**\n",
    "\n",
    "\n",
    "- Si el se trata de un error se puede borrar sin impacto (edad de 200 años)\n",
    "- Investigar la naturaleza del error antes de tomar la decisión\n",
    "- Antes de borralos habría que analizar el conjunto de datos con y sin outliers\n",
    "- Si el oultlier no cambia el resultado pero afecta a tus asunciones, se podría borrar (asunciones x ej de que es normal)\n",
    "- Si cambiaran ambos, se debería hacer el estudio con y sin outliers e indicar ambos resultados\n",
    "- Si el outlier crea una asociación significativa, se debería de borrar\n",
    "- Se puede probar con transformaciones de los datos: logarítmica, raíz cuadrada..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujamos boxplot para visualizar outliers\n",
    "\n",
    "data_numeric = data.select_dtypes(include=[np.number])\n",
    "columns = data_numeric.columns.values\n",
    "print(columns)\n",
    "\n",
    "\n",
    "order = columns = data_numeric.columns.values\n",
    "\n",
    "sns.boxplot(data=data_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Como en el caso de fare los outliers son muy grandes, no nos permiten ver bien el resto de variables, \n",
    "# por lo que los filtramos para visualizar mejor el resto de variables\n",
    "\n",
    "data_numeric_msk = data_numeric[data_numeric['fare'] < 500]\n",
    "sns.boxplot(data=data_numeric_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numeric.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se rellenan los valors de fare con la media, porque si no nos va a delvolver Nans a la hora de calcular el \n",
    "# valor z\n",
    "data[\"fare\"].fillna(np.mean(np.mean(data[\"fare\"])),inplace=True)\n",
    "data[\"fare\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_numeric = data.select_dtypes(include=[np.number])\n",
    "data_numeric.drop(['Unnamed: 0','age_imputer','age_regresion','age_knn'], axis=1, inplace=True)\n",
    "z = pd.DataFrame(np.abs(stats.zscore(data_numeric)), columns=['pclass', 'survived', 'age', 'sibsp', 'parch', 'fare', 'body',\n",
    "       'age_mean', 'age_ffill', 'age_bfill'])\n",
    "print(z)\n",
    "print(z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este resultado nos devuelve los índices no el resultado!!!\n",
    "np.where(z[\"fare\"]>=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[\"fare\"][0],z[\"fare\"][10],z[\"fare\"][11], z[\"fare\"][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"fare\"][0],data[\"fare\"][10],data[\"fare\"][11], data[\"fare\"][16], data[\"fare\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Oulier detection -- Mas de 30 algoritmos para detectar outliers\n",
    "\n",
    "#!pip install pyod  \n",
    "# pip install --upgrade pyod\n",
    "from pyod.models.knn import KNN\n",
    "import pandas as pd\n",
    " \n",
    "\n",
    "clf = KNN(contamination=0.18)\n",
    "clf.fit(data_numeric.fare)\n",
    "y_pred = clf.predict(np.isnan(data_numeric.fare).any())\n",
    "data_numeric[y_pred == 1]\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(s):\n",
    "    iqr = (np.quantile(s, 0.75))-(np.quantile(s, 0.25))\n",
    "    upper_bound = np.quantile(s, 0.75)+(1.5*iqr)\n",
    "    lower_bound = np.quantile(s, 0.25)-(1.5*iqr)\n",
    "    f = []\n",
    "    \n",
    "    for i in s:\n",
    "        if i > upper_bound:\n",
    "            f.append(i)\n",
    "        elif i < lower_bound:\n",
    "            f.append(i)\n",
    "    \n",
    "    pros = len(f)/len(s)*100\n",
    "    d = {'IQR':iqr,\n",
    "         'Upper Bound':upper_bound,\n",
    "         'Lower Bound':lower_bound,\n",
    "         'percentage outliers':pros,\n",
    "         'total outliers': len(f)}\n",
    "    d = pd.DataFrame(d.items(),columns = ['sub','values'])\n",
    "    return(d)\n",
    "\n",
    "#for column in columns:\n",
    "\n",
    "data_numeric[\"age\"].fillna(np.mean(data_numeric[\"age\"]), inplace=True)\n",
    "\n",
    "print(\"Estudio de los outliers de la variable age\")\n",
    "print(outliers(data_numeric[\"age\"]))\n",
    "print(\"Estudio de los outliers de la variable sibsp\")\n",
    "print(outliers(data_numeric[\"sibsp\"]))\n",
    "print(\"Estudio de los outliers de la variable parch\")\n",
    "print(outliers(data_numeric[\"parch\"]))\n",
    "print(\"Estudio de los outliers de la variable fare\")\n",
    "print(outliers(data_numeric[\"fare\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[columns[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data[\"age\"]>=54.5) | (data[\"age\"]<=2.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EllipticEnvelope\n",
    "\n",
    "An object for detecting outliers in a Gaussian distributed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_numeric.isnull().sum()\n",
    "#data_numeric[\"age\"].fillna(np.mean(data_numeric[\"age\"]), inplace=True)\n",
    "#data_numeric[\"body\"].fillna(np.mean(data_numeric[\"body\"]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_method = EllipticEnvelope(random_state=42).fit(data_numeric)\n",
    "\n",
    "# Los scores_pred dan una puntuación por fila\n",
    "scores_pred = outlier_method.decision_function(data_numeric)\n",
    "threshold = stats.scoreatpercentile(scores_pred, 25)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio de outliers.\n",
    "print(\"%.3f %%\" % (100*len(scores_pred[scores_pred < threshold])/len(scores_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(scores_pred, whis=3, vert=False)\n",
    "plt.title(\"Boxplot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos los umbrales\n",
    "Q1 = stats.scoreatpercentile(scores_pred, 25)\n",
    "Q3 = stats.scoreatpercentile(scores_pred, 75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Valores atípicos, valores extremos sería a partir de 3\n",
    "lim_inf = Q1 - 3*IQR\n",
    "lim_sup = Q3 + 3*IQR\n",
    "\n",
    "print(\"El límite inferior es: \", lim_inf)\n",
    "print(\"El límite superior es: \", lim_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimación outliers\n",
    "# Se busca la posición para proceder a la eliminación de outliers\n",
    "\n",
    "pos_i = np.where(scores_pred<=lim_inf)\n",
    "pos_s = np.where(scores_pred>=lim_sup)\n",
    "\n",
    "print(\"Posición de los outliers en el extremo inferior: \", pos_i)\n",
    "print(\"Posición de los outliers en el extremo superior: \", pos_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan las instancias con outliers extremos\n",
    "\n",
    "df1.drop([417, 423, 449],axis=0,inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La normalización de datos tiene por objetivo ajustar valores medidos en diferentes escalas a una escala común.\n",
    "Se recomienda en datos de entrada de ML, ya que otorga la misma importancia o peso a todas la variables.\n",
    "Se aplica a las columnas con valores numéricos.\n",
    "\n",
    "Algunos métodos (Pandas) son:\n",
    "\n",
    "- Escala de función única: se convierte cada variable en un valor comprendido entre 0 y 1 dividendo por el máximo\n",
    "- Mínimo-Máximo: se convierte cada variable en un valor comprendido entre 0 y 1 calculando la diferencia entre el valor observado y el valor mínimo y diviendo entre el rango (max-min)\n",
    "- Puntuación Z: transformar los valores a valores estándar, restando a la observación el valor de la media y dividiendo entre la desviación estándar\n",
    "\n",
    "- Recorte: limitar los valores con un máximo y un mínimo para que no superen ese umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unique_fun(df_input):\n",
    "    return df_input.apply(lambda x: ((x)/(x.max())))\n",
    "\n",
    "def minmax_norm(df_input):\n",
    "    return (df_input - df_input.min()) / (df_input.max() - df_input.min())\n",
    "\n",
    "def mean_norm(df_input):\n",
    "    return df_input.apply(lambda x: (x-x.mean())/ x.std(), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalización con scikit-learn**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "\n",
    "- Min-Max Scaler\n",
    "- Abs Mean Scaler\n",
    "- StandardScaler: Standardize features by removing the mean and scaling to unit variance z = (x - u) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaler\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    " \n",
    "x = np.random.randint(0,20,9).reshape(3,3)\n",
    "x_copy= x\n",
    "print(x)\n",
    " \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_minmax = min_max_scaler.fit_transform(x)\n",
    "print(x_minmax)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_norm(x_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max abs scaler\n",
    "\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "x_train_maxsbs = max_abs_scaler.fit_transform(x_copy)\n",
    "x_train_maxsbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis exploratorio de los datos\n",
    "# Análisis y tratamiento de valores faltantes\n",
    "# Normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
