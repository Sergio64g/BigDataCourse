{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. An√°lisis inicial de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# conda install -c conda-forge pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='images/Image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ruta = os.path.join(\"datasets\", \"titanic3.csv\")\n",
    "fichero = open(ruta)\n",
    "data = pd.read_csv(ruta)\n",
    "fichero.close()\n",
    "data.head()\n",
    "\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309</td>\n",
       "      <td>1309</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309</td>\n",
       "      <td>1308.000000</td>\n",
       "      <td>295</td>\n",
       "      <td>1307</td>\n",
       "      <td>486</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1307</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>914</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.294882</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.881135</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.295479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.809917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837836</td>\n",
       "      <td>0.486055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.413500</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.758668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.696922</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pclass     survived                  name   sex          age  \\\n",
       "count   1309.000000  1309.000000                  1309  1309  1046.000000   \n",
       "unique          NaN          NaN                  1307     2          NaN   \n",
       "top             NaN          NaN  Connolly, Miss. Kate  male          NaN   \n",
       "freq            NaN          NaN                     2   843          NaN   \n",
       "mean       2.294882     0.381971                   NaN   NaN    29.881135   \n",
       "std        0.837836     0.486055                   NaN   NaN    14.413500   \n",
       "min        1.000000     0.000000                   NaN   NaN     0.166700   \n",
       "25%        2.000000     0.000000                   NaN   NaN    21.000000   \n",
       "50%        3.000000     0.000000                   NaN   NaN    28.000000   \n",
       "75%        3.000000     1.000000                   NaN   NaN    39.000000   \n",
       "max        3.000000     1.000000                   NaN   NaN    80.000000   \n",
       "\n",
       "              sibsp        parch    ticket         fare        cabin embarked  \\\n",
       "count   1309.000000  1309.000000      1309  1308.000000          295     1307   \n",
       "unique          NaN          NaN       929          NaN          186        3   \n",
       "top             NaN          NaN  CA. 2343          NaN  C23 C25 C27        S   \n",
       "freq            NaN          NaN        11          NaN            6      914   \n",
       "mean       0.498854     0.385027       NaN    33.295479          NaN      NaN   \n",
       "std        1.041658     0.865560       NaN    51.758668          NaN      NaN   \n",
       "min        0.000000     0.000000       NaN     0.000000          NaN      NaN   \n",
       "25%        0.000000     0.000000       NaN     7.895800          NaN      NaN   \n",
       "50%        0.000000     0.000000       NaN    14.454200          NaN      NaN   \n",
       "75%        1.000000     0.000000       NaN    31.275000          NaN      NaN   \n",
       "max        8.000000     9.000000       NaN   512.329200          NaN      NaN   \n",
       "\n",
       "       boat        body     home.dest  \n",
       "count   486  121.000000           745  \n",
       "unique   27         NaN           369  \n",
       "top      13         NaN  New York, NY  \n",
       "freq     39         NaN            64  \n",
       "mean    NaN  160.809917           NaN  \n",
       "std     NaN   97.696922           NaN  \n",
       "min     NaN    1.000000           NaN  \n",
       "25%     NaN   72.000000           NaN  \n",
       "50%     NaN  155.000000           NaN  \n",
       "75%     NaN  256.000000           NaN  \n",
       "max     NaN  328.000000           NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.294881588999236"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()[\"pclass\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe(include = \"all\")\n",
    "\n",
    "#data.describe(include = \"all\").transpose()\n",
    "\n",
    "# unique: cantidad de valores √∫nicos.\n",
    "# top: valor √∫nico con m√°s repeticiones.\n",
    "# freq: cantidad de veces que aparece el valor m√°s repetido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('New York, NY', 29.8811345124283)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"home.dest\"].describe()['top'], data[\"age\"].describe()['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    pct_missing = np.mean(data[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pclass     1309 non-null   int64  \n",
      " 1   survived   1309 non-null   int64  \n",
      " 2   name       1309 non-null   object \n",
      " 3   sex        1309 non-null   object \n",
      " 4   age        1046 non-null   float64\n",
      " 5   sibsp      1309 non-null   int64  \n",
      " 6   parch      1309 non-null   int64  \n",
      " 7   ticket     1309 non-null   object \n",
      " 8   fare       1308 non-null   float64\n",
      " 9   cabin      295 non-null    object \n",
      " 10  embarked   1307 non-null   object \n",
      " 11  boat       486 non-null    object \n",
      " 12  body       121 non-null    float64\n",
      " 13  home.dest  745 non-null    object \n",
      "dtypes: float64(3), int64(4), object(7)\n",
      "memory usage: 143.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1309, 14), 18326)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.312469</td>\n",
       "      <td>-0.408106</td>\n",
       "      <td>0.060832</td>\n",
       "      <td>0.018322</td>\n",
       "      <td>-0.558629</td>\n",
       "      <td>-0.034642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>-0.312469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.055513</td>\n",
       "      <td>-0.027825</td>\n",
       "      <td>0.082660</td>\n",
       "      <td>0.244265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.408106</td>\n",
       "      <td>-0.055513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.243699</td>\n",
       "      <td>-0.150917</td>\n",
       "      <td>0.178739</td>\n",
       "      <td>0.058809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>0.060832</td>\n",
       "      <td>-0.027825</td>\n",
       "      <td>-0.243699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.373587</td>\n",
       "      <td>0.160238</td>\n",
       "      <td>-0.099961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>0.018322</td>\n",
       "      <td>0.082660</td>\n",
       "      <td>-0.150917</td>\n",
       "      <td>0.373587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221539</td>\n",
       "      <td>0.051099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>-0.558629</td>\n",
       "      <td>0.244265</td>\n",
       "      <td>0.178739</td>\n",
       "      <td>0.160238</td>\n",
       "      <td>0.221539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>-0.034642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058809</td>\n",
       "      <td>-0.099961</td>\n",
       "      <td>0.051099</td>\n",
       "      <td>-0.043110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pclass  survived       age     sibsp     parch      fare      body\n",
       "pclass    1.000000 -0.312469 -0.408106  0.060832  0.018322 -0.558629 -0.034642\n",
       "survived -0.312469  1.000000 -0.055513 -0.027825  0.082660  0.244265       NaN\n",
       "age      -0.408106 -0.055513  1.000000 -0.243699 -0.150917  0.178739  0.058809\n",
       "sibsp     0.060832 -0.027825 -0.243699  1.000000  0.373587  0.160238 -0.099961\n",
       "parch     0.018322  0.082660 -0.150917  0.373587  1.000000  0.221539  0.051099\n",
       "fare     -0.558629  0.244265  0.178739  0.160238  0.221539  1.000000 -0.043110\n",
       "body     -0.034642       NaN  0.058809 -0.099961  0.051099 -0.043110  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separar columnas num√©ricas del resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas num√©ricas: \n",
      "['pclass' 'survived' 'age' 'sibsp' 'parch' 'fare' 'body']\n",
      "\n",
      "\n",
      "Columnas NO num√©ricas: \n",
      "['name' 'sex' 'ticket' 'cabin' 'embarked' 'boat' 'home.dest']\n"
     ]
    }
   ],
   "source": [
    "data_numeric = data.select_dtypes(include=[np.number])\n",
    "numeric_cols = data_numeric.columns.values\n",
    "\n",
    "data_non_numeric = data.select_dtypes(exclude=[np.number])\n",
    "non_numeric_cols = data_non_numeric.columns.values\n",
    "\n",
    "print(\"Columnas num√©ricas: \")\n",
    "print(numeric_cols)\n",
    "print(\"\\n\")\n",
    "print(\"Columnas NO num√©ricas: \")\n",
    "print(non_numeric_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An√°lisis exploratorio con pandas profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se pueden generar los reportes mediante dos interfaces: widgets y HTML report\n",
    "# El principal inconveniente es el timpo que tarda en generar el reporte\n",
    "# Para grandes cantidades de datos, conviene seleccionar las variables que m√°s nos interesen.\n",
    "\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "#from pandas_profiling.utils.cache import cache_file\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Profiling Report\n",
    "profile = ProfileReport(\n",
    "    data, title=\"Titanic Dataset\", html={\"style\": {\"full_width\": True}}, sort=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(\"your_report.html\")\n",
    "\n",
    "# As a string\n",
    "json_data = profile.to_json()\n",
    "\n",
    "# As a file\n",
    "profile.to_file(\"your_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encontrar los valores faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores nulos por columna\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Cantidad valores nulos\n",
    "print(data.isnull().sum().sum())\n",
    "\n",
    "# numero de no nulos por fila\n",
    "print(data.count(axis=1))\n",
    "\n",
    "# N√∫mero de nulos por fila\n",
    "print(data.shape[1] - data.count(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro de las filas con valores faltantes\n",
    "data[data.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos podemos crear un mapa de calor de los datos faltantes\n",
    "# Los amarillos ser√≠an los valores faltantes de cada variable\n",
    "\n",
    "cols = data.columns \n",
    "colours = ['#5A9', '#ffff00'] \n",
    "sns.heatmap(data[cols].isnull(), cmap=sns.color_palette(colours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    pct_missing = np.mean(data[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eliminar datos si hay valores faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si optaramos por borrar\n",
    "\n",
    "# data.dropna(how=\"any\") #Borra todas las filas en las que hay al menos un vac√≠o\n",
    "# data.dropna(how=\"all\") # Borra las filas que tienen todo vac√≠o\n",
    "# data.dropna(thresh=2) # Conserva las filas que tienen al menos dos valores vac√≠os\n",
    "# data.dropna(subset= [\"boat\"]) # Elimina las filas que tienen boat vac√≠o\n",
    "# data.dropna(axis=\"columns\", how=\"any\") # Elimina columnas con al menos un vac√≠o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_mean\"]=data[\"age\"]\n",
    "data\n",
    "\n",
    "# Se puede rellenar los valores faltantes con la media\n",
    "data[\"age_mean\"].fillna(np.mean(np.mean(data[\"age_mean\"])),inplace=True)\n",
    "data[data[\"age\"].isnull()]\n",
    "\n",
    "# Se puede rellenar los valores faltantes con un valor concreto\n",
    "# data[\"age_mean\"].fillna(18,inplace=True)\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En series temporales (el valor m√°s pr√≥ximo o parecido suele ser el anterior/posterior), no conviene\n",
    "# rellenar con la media, se suele hacer con un par de m√©todos que rellenan el valor anterior o el posterior\n",
    "\n",
    "# Method to use for filling holes in reindexed Series \n",
    "# pad / ffill: propagate last valid observation forward to next valid \n",
    "# backfill / bfill: use next valid observation to fill gap.\n",
    "\n",
    "#under_age['Age'] = np.nan\n",
    "\n",
    "#data.drop(\"age_ffill\", axis=1, inplace=True)\n",
    "#data.drop(\"age_bfill\", axis=1, inplace=True)\n",
    "\n",
    "data[\"age_ffill\"] = data[\"age\"]\n",
    "data[\"age_bfill\"] = data[\"age\"]\n",
    "\n",
    "data[\"age_ffill\"].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "data[\"age_bfill\"].fillna(method=\"bfill\",inplace=True)\n",
    "data.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"age\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn.impute.SimpleImputer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(\"age_imputer\",axis=1, inplace=True)\n",
    "data[\"age_imputer\"] = data[\"age\"]\n",
    "\n",
    "#imp_mean.fit(data[\"age_imputer\"].reshape(-1,1))\n",
    "\n",
    "\n",
    "data['age_imputer']=pd.DataFrame(imp_mean.fit_transform(data[\"age_imputer\"].values.reshape(-1, 1)))\n",
    "\n",
    "data['age_imputer'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputaci√≥n de Regresi√≥n --> IterativeImputer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#data.drop(\"age_regresion\",axis=1, inplace=True)\n",
    "data[\"age_regresion\"] = data[\"age\"]\n",
    "\n",
    "reg_imputer = IterativeImputer(max_iter=10, random_state=123)\n",
    "\n",
    "data['age_regresion']=pd.DataFrame(reg_imputer.fit_transform(data[\"age_regresion\"].values.reshape(-1,1)))\n",
    "\n",
    "data['age_regresion'].isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age_regresion'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputaci√≥n Knn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_knn\"] = data[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "knn_imputer.fit(data[\"age_knn\"].values.reshape(-1,1))\n",
    "\n",
    "knn_imputer.transform(data[\"age_knn\"].values.reshape(-1,1))\n",
    "\n",
    "#data['age_knn']=pd.DataFrame(knn_imputer.fit_transform(data[\"age_knn\"].values.reshape(-1,1)))\n",
    "data['age_knn'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Con strings se pueden reemplazar los datos nan con el valor que se repite con m√°s frecuencia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\")\n",
    "\n",
    "print(data[\"home.dest\"].value_counts().idxmax())\n",
    "print(data[\"home.dest\"].isnull().sum())\n",
    "\n",
    "data[\"home.dest\"] = data[\"home.dest\"].fillna(data[\"home.dest\"].value_counts().idxmax())\n",
    "print(data[\"home.dest\"].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"home.dest\"].value_counts()\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = pd.Series(['a','b','c','a','c','a','g'])\n",
    "serie.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_dataset\n",
    "df\n",
    "# eliminar\n",
    "# Eliminaci√≥n de los duplicados en una columna definida\n",
    "df2 = df.drop_duplicates(subset=\"Gender\", keep='last', inplace=False)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tratamiento de outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los outliers o caso at√≠picos son datos muy diferentes a los dem√°s, debens er contemplados en el contexto del del an√°lisis, pero no siempre se pueden clasificar como buenos o malos.\n",
    "\n",
    "Se suele establecer un umbral para clasificar las observaciones como outliers o no.\n",
    "\n",
    "Pueden ser datos observados o datos que se deben a un error.\n",
    "\n",
    "El problema viene cuando distorsionan de forma problem√°tica el comportamiento del an√°lisis o de los modelos. \n",
    "Incrementan la varianza, y si no est√°n distribuidos aleatoriamente pueden reducir la normalidad de la muestra.\n",
    "Tambi√©n distorsionan el coeficiente de correlaci√≥n, media, desviaci√≥n est√°ndar... y en consecuencia todos los an√°lisis estad√≠sticos que las utilizan\n",
    "\n",
    "Hay varios m√©todos para reconocerlos, algunos √∫tiles son: \n",
    "- Visualizaciones: boxplot, scatterplot, histograma\n",
    "- Estad√≠sticos: Z score \n",
    "    - Para muestras peque√±as +,-2,5 veces z\n",
    "    - Para muestras grandes +,-3 veces z\n",
    "- Estad√≠sticos: IQR\n",
    "    - 1,5 veces IQR\n",
    "    - Cuando supera +-3IQR se consideran **outliers extremos**\n",
    "- EllipticEnvelope \n",
    "    \n",
    "**el algoritmo de envolvente el√≠ptica** crea superficies el√≠pticas en torno a la nube de puntos, y cuanto m√°s alejados est√°n los puntos de dicha nube, mayor probabilidad de que sean outliers. \n",
    "\n",
    "Para construir las superficies el√≠pticas, loa datos se van a centrar (con respecto a la mediana, resta) y escalar (con respecto al IQR, divisi√≥n).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers: To Drop or Not to Drop**\n",
    "\n",
    "\n",
    "- Si el se trata de un error se puede borrar sin impacto (edad de 200 a√±os)\n",
    "- Investigar la naturaleza del error antes de tomar la decisi√≥n\n",
    "- Antes de borralos habr√≠a que analizar el conjunto de datos con y sin outliers\n",
    "- Si el oultlier no cambia el resultado pero afecta a tus asunciones, se podr√≠a borrar (asunciones x ej de que es normal)\n",
    "- Si cambiaran ambos, se deber√≠a hacer el estudio con y sin outliers e indicar ambos resultados\n",
    "- Si el outlier crea una asociaci√≥n significativa, se deber√≠a de borrar\n",
    "- Se puede probar con transformaciones de los datos: logar√≠tmica, ra√≠z cuadrada..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dibujamos boxplot para visualizar outliers\n",
    "\n",
    "data_numeric = data.select_dtypes(include=[np.number])\n",
    "columns = data_numeric.columns.values\n",
    "print(columns)\n",
    "\n",
    "\n",
    "order = columns = data_numeric.columns.values\n",
    "\n",
    "sns.boxplot(data=data_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Como en el caso de fare los outliers son muy grandes, no nos permiten ver bien el resto de variables, \n",
    "# por lo que los filtramos para visualizar mejor el resto de variables\n",
    "\n",
    "data_numeric_msk = data_numeric[data_numeric['fare'] < 500]\n",
    "sns.boxplot(data=data_numeric_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numeric.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se rellenan los valors de fare con la media, porque si no nos va a delvolver Nans a la hora de calcular el \n",
    "# valor z\n",
    "data[\"fare\"].fillna(np.mean(np.mean(data[\"fare\"])),inplace=True)\n",
    "data[\"fare\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_numeric = data.select_dtypes(include=[np.number])\n",
    "data_numeric.drop(['Unnamed: 0','age_imputer','age_regresion','age_knn'], axis=1, inplace=True)\n",
    "z = pd.DataFrame(np.abs(stats.zscore(data_numeric)), columns=['pclass', 'survived', 'age', 'sibsp', 'parch', 'fare', 'body',\n",
    "       'age_mean', 'age_ffill', 'age_bfill'])\n",
    "print(z)\n",
    "print(z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este resultado nos devuelve los √≠ndices no el resultado!!!\n",
    "np.where(z[\"fare\"]>=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[\"fare\"][0],z[\"fare\"][10],z[\"fare\"][11], z[\"fare\"][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"fare\"][0],data[\"fare\"][10],data[\"fare\"][11], data[\"fare\"][16], data[\"fare\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Oulier detection -- Mas de 30 algoritmos para detectar outliers\n",
    "\n",
    "#!pip install pyod  \n",
    "# pip install --upgrade pyod\n",
    "from pyod.models.knn import KNN\n",
    "import pandas as pd\n",
    " \n",
    "\n",
    "clf = KNN(contamination=0.18)\n",
    "clf.fit(data_numeric.fare)\n",
    "y_pred = clf.predict(np.isnan(data_numeric.fare).any())\n",
    "data_numeric[y_pred == 1]\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(s):\n",
    "    iqr = (np.quantile(s, 0.75))-(np.quantile(s, 0.25))\n",
    "    upper_bound = np.quantile(s, 0.75)+(1.5*iqr)\n",
    "    lower_bound = np.quantile(s, 0.25)-(1.5*iqr)\n",
    "    f = []\n",
    "    \n",
    "    for i in s:\n",
    "        if i > upper_bound:\n",
    "            f.append(i)\n",
    "        elif i < lower_bound:\n",
    "            f.append(i)\n",
    "    \n",
    "    pros = len(f)/len(s)*100\n",
    "    d = {'IQR':iqr,\n",
    "         'Upper Bound':upper_bound,\n",
    "         'Lower Bound':lower_bound,\n",
    "         'percentage outliers':pros,\n",
    "         'total outliers': len(f)}\n",
    "    d = pd.DataFrame(d.items(),columns = ['sub','values'])\n",
    "    return(d)\n",
    "\n",
    "#for column in columns:\n",
    "\n",
    "data_numeric[\"age\"].fillna(np.mean(data_numeric[\"age\"]), inplace=True)\n",
    "\n",
    "print(\"Estudio de los outliers de la variable age\")\n",
    "print(outliers(data_numeric[\"age\"]))\n",
    "print(\"Estudio de los outliers de la variable sibsp\")\n",
    "print(outliers(data_numeric[\"sibsp\"]))\n",
    "print(\"Estudio de los outliers de la variable parch\")\n",
    "print(outliers(data_numeric[\"parch\"]))\n",
    "print(\"Estudio de los outliers de la variable fare\")\n",
    "print(outliers(data_numeric[\"fare\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[columns[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data[\"age\"]>=54.5) | (data[\"age\"]<=2.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EllipticEnvelope\n",
    "\n",
    "An object for detecting outliers in a Gaussian distributed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_numeric.isnull().sum()\n",
    "#data_numeric[\"age\"].fillna(np.mean(data_numeric[\"age\"]), inplace=True)\n",
    "#data_numeric[\"body\"].fillna(np.mean(data_numeric[\"body\"]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_method = EllipticEnvelope(random_state=42).fit(data_numeric)\n",
    "\n",
    "# Los scores_pred dan una puntuaci√≥n por fila\n",
    "scores_pred = outlier_method.decision_function(data_numeric)\n",
    "threshold = stats.scoreatpercentile(scores_pred, 25)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio de outliers.\n",
    "print(\"%.3f %%\" % (100*len(scores_pred[scores_pred < threshold])/len(scores_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(scores_pred, whis=3, vert=False)\n",
    "plt.title(\"Boxplot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos los umbrales\n",
    "Q1 = stats.scoreatpercentile(scores_pred, 25)\n",
    "Q3 = stats.scoreatpercentile(scores_pred, 75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Valores at√≠picos, valores extremos ser√≠a a partir de 3\n",
    "lim_inf = Q1 - 3*IQR\n",
    "lim_sup = Q3 + 3*IQR\n",
    "\n",
    "print(\"El l√≠mite inferior es: \", lim_inf)\n",
    "print(\"El l√≠mite superior es: \", lim_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimaci√≥n outliers\n",
    "# Se busca la posici√≥n para proceder a la eliminaci√≥n de outliers\n",
    "\n",
    "pos_i = np.where(scores_pred<=lim_inf)\n",
    "pos_s = np.where(scores_pred>=lim_sup)\n",
    "\n",
    "print(\"Posici√≥n de los outliers en el extremo inferior: \", pos_i)\n",
    "print(\"Posici√≥n de los outliers en el extremo superior: \", pos_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan las instancias con outliers extremos\n",
    "\n",
    "df1.drop([417, 423, 449],axis=0,inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Normalizaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La normalizaci√≥n de datos tiene por objetivo ajustar valores medidos en diferentes escalas a una escala com√∫n.\n",
    "Se recomienda en datos de entrada de ML, ya que otorga la misma importancia o peso a todas la variables.\n",
    "Se aplica a las columnas con valores num√©ricos.\n",
    "\n",
    "Algunos m√©todos (Pandas) son:\n",
    "\n",
    "- Escala de funci√≥n √∫nica: se convierte cada variable en un valor comprendido entre 0 y 1 dividendo por el m√°ximo\n",
    "- M√≠nimo-M√°ximo: se convierte cada variable en un valor comprendido entre 0 y 1 calculando la diferencia entre el valor observado y el valor m√≠nimo y diviendo entre el rango (max-min)\n",
    "- Puntuaci√≥n Z: transformar los valores a valores est√°ndar, restando a la observaci√≥n el valor de la media y dividiendo entre la desviaci√≥n est√°ndar\n",
    "\n",
    "- Recorte: limitar los valores con un m√°ximo y un m√≠nimo para que no superen ese umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unique_fun(df_input):\n",
    "    return df_input.apply(lambda x: ((x)/(x.max())))\n",
    "\n",
    "def minmax_norm(df_input):\n",
    "    return (df_input - df_input.min()) / (df_input.max() - df_input.min())\n",
    "\n",
    "def mean_norm(df_input):\n",
    "    return df_input.apply(lambda x: (x-x.mean())/ x.std(), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizaci√≥n con scikit-learn**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "\n",
    "- Min-Max Scaler\n",
    "- Abs Mean Scaler\n",
    "- StandardScaler: Standardize features by removing the mean and scaling to unit variance z = (x - u) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaler\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    " \n",
    "x = np.random.randint(0,20,9).reshape(3,3)\n",
    "x_copy= x\n",
    "print(x)\n",
    " \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_minmax = min_max_scaler.fit_transform(x)\n",
    "print(x_minmax)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_norm(x_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max abs scaler\n",
    "\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "x_train_maxsbs = max_abs_scaler.fit_transform(x_copy)\n",
    "x_train_maxsbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis exploratorio de los datos\n",
    "# An√°lisis y tratamiento de valores faltantes\n",
    "# Normalizaci√≥n de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
